{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Prediction\n",
    "\n",
    "This refers to the https://www.kaggle.com/c/house-prices-advanced-regression-techniques#description competition\n",
    "\n",
    "In this notebook I will outline general major steps and build a baseline model.\n",
    "\n",
    "Your job in the course of this session (and the next few weeks) is to do feature engineering for this model.\n",
    "\n",
    "Keep in mind, the baseline model we will look at is a Random Forests model which is tree based model. Make features accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Note, if you are getting ideas for feature engineering from kernels. \n",
    "\n",
    "Feature engineering that deal with feature transformations like log transfoming, etc. Don't have great impcact on our model since we are using tree based methods. \n",
    "\n",
    "If you chose to fit linear models, I would highly suggest making such transformations.  \n",
    "\n",
    "I will give some guidelines for creating features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "For continous features, handle missing values by using infomration in the **train** data.\n",
    "\n",
    "Some of the continous features should be imputed to 0 rather than the mean. These are columns of things like garage size, if it is missing, it probably means this person doens't have a garage. I labeled this in a list as impute to zero.\n",
    "\n",
    "For categorical feature, impute mising values to a new value called \"missing\". \n",
    "\n",
    "\n",
    "(Hint 1: We did something similar to this in our titanic jupyter notebook)\n",
    "\n",
    "\n",
    "(Hint 2: Do not overthink the imputation, basic imputation works fine for this problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Goes Here\n",
    "impute_to_0 = ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    " 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features by Interacting existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here is an example feature to make\n",
    "for df in train,test:\n",
    "    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create more features here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Feature Engineering\n",
    "\n",
    "### Create Date Based Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encode Categorical Features\n",
    "\n",
    "(hint: use sklearn one_hot_encoder: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outlier of Continous Features  \n",
    "\n",
    "(hint: we did this for fare and age in titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score # This computes cross validation holdout score\n",
    "reg = RandomForestRegressor()\n",
    "\n",
    "cv_score = cross_val_score(reg,train.drop([\"SalePrice\",\"Id\"],axis=1),train[\"SalePrice\"],scoring='mean_squared_error')\n",
    "print(f\"The cv RMSE is : {cv_score.mean()**0.5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_science_club]",
   "language": "python",
   "name": "conda-env-data_science_club-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
