{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slides can be found here: \n",
    "https://docs.google.com/presentation/d/1lSzs0hmy6-aqAyRhg30wSoxdjly1RsyfmK0vQfS03Ns/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can us the pandas read_cvs to function to read the train and test data\n",
    "Since the train & test data is already in our directory, \n",
    "we don't have to specify the full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"titanic_train.csv\") \n",
    "test = pd.read_csv(\"titanic_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.to_frame().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid performing engineering seperatly on training and testing data, we will \"concat\" the train and data set.\n",
    "\n",
    "axis = 0 means concating row wise\n",
    "axis = 1 means concating column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full DataFrame\n",
    "full = pd.concat([train,test],axis=0,ignore_index=True,sort=True)\n",
    "\n",
    "# Create submission example\n",
    "sub_example = full[[\"PassengerId\",\"Survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some ML algorithms are not robust to missing values, we need to remove NAs from our data set.\n",
    "\n",
    "Our data set is very small, we cannot afford to drop columns with missing values. \n",
    "\n",
    "In such cases, we use NA imputing to resolve this issue.\n",
    "\n",
    "Imputing changes the value of NAs to something which the ML algorithm  can understand, while mitigating the risk of adding $influencial$ values. \n",
    "\n",
    "For continous features, we usually impute missing values by the mean or the mode of the **training** data.\n",
    "\n",
    "For categorical featres, we usually impute missing values by a new category called \"Missing\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a for loop over columns of float dtypes: \n",
    "for col in full.select_dtypes([\"float\",\"int\"]).columns: \n",
    "    if col != \"Survived\": # Making sure we are not imputing the Survived values\n",
    "        # Imputing to the mean of the training set\n",
    "        full.loc[full[col].isna(),col] = train[col].mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a for loop over columns of object dtypes, and impute missing values to a new category called \"Missing\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will come up with features that are not there in the data set.\n",
    "For example, the data set doesn't include any features that detail whether a passenger is married.\n",
    "We can include this feature into our model by using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Features Example\n",
    "full[\"IsMarriedMan\"] = ((full[\"Sex\"] == \"male\")&(full[\"SibSp\"]>0)&(full[\"Age\"]>18))*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's think of some other features which will be useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Features Here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some other features that you think we should add into our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Features\n",
    "\n",
    "Let's Create a feature which extract the title from the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Here:\n",
    "import re\n",
    "full[\"Title\"] = full[\"Name\"]\n",
    "for row in range(0,full.shape[0]):\n",
    "    full.loc[row,\"Title\"] = re.sub('(.*, )|(\\\\..*)',\"\",full[\"Name\"].loc[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.Series(index=full[\"Title\"].unique())\n",
    "for each in dist.index:\n",
    "    dist.loc[each] = sum(full[\"Title\"]==each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding overfitting to granular data\n",
    "\n",
    "We see that there are many categorical levels which have very few data points.\n",
    "\n",
    "We should remove them to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change names\n",
    "full.loc[full.Title.isin([\"Don\",\"Capt\",\"Major\",\"Col\",\"Jonkheer\"]),\"Title\"] = \"Mr\"\n",
    "full.loc[full.Title.isin([\"Ms\",\"the Countess\",\"Lady\"]),\"Title\"] = \"Miss\"\n",
    "full.loc[full.Title.isin([\"Mme\",\"Mlle\",\"Dona\"]),\"Title\"] = \"Mrs\"\n",
    "full.loc[(full.Title==\"Sir\"),\"Title\"] = \"Mr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_2 = pd.Series(index=full[\"Title\"].unique())\n",
    "for each in dist_2.index:\n",
    "    dist_2.loc[each] = sum(full[\"Title\"]==each)\n",
    "dist_2\n",
    "\n",
    "# Is 8 to little? That is for you to decide..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Let's try and find weird outlier. Many ML algorithms are sensitive to outliers. Clipping values is usually very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "for col in train.select_dtypes([\"float\",\"int\"]).columns: \n",
    "    train[col].plot(kind=\"hist\")\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.loc[full[\"Age\"].idxmin(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[full[\"Age\"]<2] # Only looking at training data! No Cheating :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make feature for baby? Clip low values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare\n",
    "train.loc[full[\"Fare\"]>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new feature?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless features\n",
    "full.drop([\"Name\",\"Ticket\",\"Cabin\",'PassengerId',\"Embarked\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode Variables\n",
    "full = pd.get_dummies(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "train_fe = full[~full.Survived.isna()].loc[0:599]\n",
    "valid_fe = full[~full.Survived.isna()].loc[600:891]\n",
    "test_fe = full[full.Survived.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "\n",
    "## Next Time..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
